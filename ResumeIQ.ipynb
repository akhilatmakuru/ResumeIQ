{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b74f4131",
   "metadata": {},
   "source": [
    "# ResumeIQ: AI-Powered Resume Understanding & Q&A\n",
    "\n",
    "### ResumeIQ is a Python-based AI tool that reads multi-page resumes and extracts structured, recruiter-ready information using large language models (LLMs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a77de273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Imports\n",
    "import pdfplumber\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6af3d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load PDF\n",
    "pdf_path = \"/Users/Akhila/Desktop/Py_Images/Resume.pdf\"\n",
    "text = \"\"\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for page in pdf.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            text += page_text + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0bffa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Clean the text\n",
    "# Removes emails, phone numbers, links, newlines, extra spaces, bullets, etc.\n",
    "clean_text = re.sub(r\"\\S+@\\S+\", \"\", text)  # emails\n",
    "clean_text = re.sub(r\"\\+?\\d[\\d\\s\\-\\(\\)]{7,}\", \"\", clean_text)  # phone numbers\n",
    "clean_text = re.sub(r\"(LinkedIn|Github|GitHub|www\\.\\S+)\", \"\", clean_text)  # links\n",
    "clean_text = re.sub(r\"[\\n\\r]+\", \" \", clean_text)  # newlines\n",
    "clean_text = re.sub(r\"[\\(\\)\\[\\];•]+\", \"\", clean_text)  # special chars\n",
    "clean_text = re.sub(r\"\\s+\", \" \", clean_text)  # extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16dbbbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Chunk the text\n",
    "def chunk_text(text, chunk_size=100):\n",
    "    words = text.split()\n",
    "    chunks = [\" \".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_text(clean_text, chunk_size=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b86dde17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Load LLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed203d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Define Q&A function with better instructions\n",
    "def answer_question(question, chunks, max_length=128):\n",
    "    answers = []\n",
    "    for chunk in chunks:\n",
    "        prompt = (\n",
    "            f\"Read the following resume context and answer the question in **single short sentence**. \"\n",
    "            f\"Ignore names, emails, phone numbers, links, publications, awards, dates, and formatting.\\n\\n\"\n",
    "            f\"Context: {chunk}\\nQuestion: {question}\\nAnswer:\"\n",
    "        )\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n",
    "        outputs = model.generate(**inputs, max_length=max_length)\n",
    "        ans = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "        # Filter out any leftover irrelevant data\n",
    "        ans = re.sub(r\"(Akhila|ATMAKURU|LinkedIn|Github|Ph\\.D\\.|Master|University|Cranfield|Reading|UK|India)\", \"\", ans, flags=re.IGNORECASE).strip()\n",
    "        if ans and ans.lower() != \"not mentioned\":\n",
    "            answers.append(ans)\n",
    "    # Pick the most frequent / longest / most complete answer\n",
    "    if not answers:\n",
    "        return \"Not mentioned\"\n",
    "    return max(answers, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "248de00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Questions\n",
    "questions = [\n",
    "    \"What is the main skill of the candidate?\",\n",
    "    \"What is the candidate's highest education?\",\n",
    "    \"What Skills does the candidate have?\",\n",
    "    \"What are the publications?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9667773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is the main skill of the candidate?\n",
      "A: AI and Machine Learning Engineer\n",
      "\n",
      "Q: What is the candidate's highest education?\n",
      "A: Doctor of Philosophy  in Artificial Intelligence\n",
      "\n",
      "Q: What Skills does the candidate have?\n",
      "A: Expert in designing, developing, and deploying advanced deep learning models and architectures for large-scale, data-driven applications.\n",
      "\n",
      "Q: What are the publications?\n",
      "A: \"Transfer Learning for the Cognitive Staging Prediction in Alzheimer’s Disease\" ACAIN 2024, LNCS, Springer,2025 \"Sensitivity Analysis for Feature Importance in Predicting Alzheimer’s Disease\" ACAIN 2023, LNCS, Springer,2024 \"Improved Filter-Based Feature Selection Using Correlation and Clustering Techniques\" LOD 2023, LNCS, Springer,2024.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Get clean answers\n",
    "for q in questions:\n",
    "    ans = answer_question(q, chunks)\n",
    "    print(f\"Q: {q}\\nA: {ans}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16702285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
